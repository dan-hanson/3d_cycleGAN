"""
3D CycleGAN for Synthetic MRI Modality Translation - Training Script

Objective:
Train a 3D CycleGAN model to translate between paired MRI modalities using
preprocessed data. This script is designed to work with data generated by
the `data_preprocessing.py` script (using its original settings: min-max
normalization to [0, 1] and outputting splits to `brats_split_01` or similar).

This script handles:
- Loading the [0, 1] normalized data.
- Selecting the correct channels based on the preprocessing script's output order.
- Rescaling the data to [-1, 1] for compatibility with the GAN's Tanh output.
- Applying data augmentation using Torchio.
- Training the CycleGAN using Adversarial, Cycle-Consistency, Identity, and Intensity losses.
- Performing validation using PSNR and SSIM metrics on a held-out set.
- Implementing Learning Rate scheduling.
- Saving checkpoints (including optimizer and scheduler states).
- Logging metrics using JSON files and TensorBoard.
- Generating visualization plots.

Supported Mappings (via --mapping_type):
    - "t2_flair": Translates T2 <-> FLAIR
    - "t1_contrast": Translates T1 <-> T1CE

Assumed Preprocessing Output Channel Order:
    The .npy files produced by `data_preprocessing.py` should have channels ordered as:
    [FLAIR(0), T1CE(1), T2(2), T1(3)]

Recommended Data Input:
    Use the output of the `split_dataset` function from `data_preprocessing.py`.
    Point --data_dir to the `train/images` folder within the split output.
    Point --val_data_dir to the `val/images` folder within the split output.

Example Usage:
    # Train T2 <-> FLAIR mapping
    # (Use ^ for Windows CMD line continuation, \ for Linux/macOS)
    python train_cycleGAN.py ^
        --mapping_type t2_flair ^
        --epochs 150 ^
        --data_dir path/to/data/processed_data/brats128_training/images ^
        --val_data_dir path/to/data/processed_data/brats128_validation/images ^
        --output_base_dir ./output ^
        --use_tb

    # Resume T1 <-> T1CE training
    python train_cycleGAN.py ^
        --mapping_type t1_contrast ^
        --epochs 200 ^
        --data_dir path/to/data/processed_data/brats128_training/images ^
        --val_data_dir path/to/data/processed_data/brats128_validation/images ^
        --output_base_dir ./output ^
        --resume ./output/t1_contrast/checkpoints/checkpoint_t1_contrast_epoch099_....pth ^
        --use_tb

Environment Setup:
    conda activate your_env_name
    # Install PyTorch matching your CUDA version (see pytorch.org)
    # Example for CUDA 12.1 (compatible with driver supporting 12.8):
    # pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    pip install numpy matplotlib tqdm torchsummary tensorboard torchio torchmetrics
    # Ensure augmentation.py (with display_random_slices) is accessible
"""

import os
import datetime
import random
import numpy as np
import matplotlib.pyplot as plt
from glob import glob
import argparse
import json
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
from torchsummary import summary
from torch.utils.tensorboard import SummaryWriter
from utils import Logger, update_image_pool, Discriminator3D, Generator3D, ResNetBlock3D, PairedPreprocessedDataset, save_models
import torchio as tio
import sys

# --- Import Metrics ---
try:
    import torchmetrics
    from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure
except ImportError:
    print("Error: torchmetrics not found. Please install it: pip install torchmetrics", file=sys.stderr)
    # Define dummy classes if not found, evaluation will fail later if used
    PeakSignalNoiseRatio = type('DummyMetric', (object,), {'to': lambda self, device: self, 'reset': lambda self: None, 'update': lambda self, *args: None, 'compute': lambda self: torch.tensor(0.0)})
    StructuralSimilarityIndexMeasure = type('DummyMetric', (object,), {'to': lambda self, device: self, 'reset': lambda self: None, 'update': lambda self, *args: None, 'compute': lambda self: torch.tensor(0.0)})

# --- Import display_random_slices ---
try:
    from augmentation import display_random_slices
except ImportError:
    print("Warning: augmentation.py not found. display_random_slices will not be available.")
    def display_random_slices(*args, **kwargs):
        print("display_random_slices unavailable (augmentation.py not found).")

# --- torch.compile error suppression (optional) ---
# Can be enabled if torch.compile is used and causes issues
# Moved print statement to main script guard
try:
    import torch._dynamo
    torch._dynamo.config.suppress_errors = True
    # print("TorchDynamo error suppression enabled.")
except ImportError:
    pass # Ignore if torch._dynamo not found
    # print("torch._dynamo not found, assuming older PyTorch version or no compile usage.")

# --- Sample visualization ---
try:
    # Assuming evaluation.py is in the same directory or accessible
    from evaluation import visualize_sample_translations
except ImportError:
    print("Warning: Could not import visualize_sample_translations from evaluation.py. Skipping visualization.", file=sys.stderr)
    visualize_sample_translations = None # Set to None to prevent errors

# ------------------------------
# Utility: Checkpoint saving and loading
# ------------------------------
def save_checkpoint(epoch, g_model_AtoB, g_model_BtoA, d_model_A, d_model_B,
                    optimizer_G, optimizer_D_A, optimizer_D_B,
                    scheduler_G, scheduler_D_A, scheduler_D_B,
                    mapping_type, n_resnet_val, # Pass n_resnet explicitly
                    checkpoint_dir='./checkpoints'):
    """Saves complete training state (models, optimizers, schedulers, epoch, n_resnet)."""
    if not os.path.exists(checkpoint_dir):
        os.makedirs(checkpoint_dir)
    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    checkpoint = {
        'epoch': epoch,
        'g_model_AtoB_state': g_model_AtoB.state_dict(),
        'g_model_BtoA_state': g_model_BtoA.state_dict(),
        'd_model_A_state': d_model_A.state_dict(),
        'd_model_B_state': d_model_B.state_dict(),
        'optimizer_G_state': optimizer_G.state_dict(),
        'optimizer_D_A_state': optimizer_D_A.state_dict(),
        'optimizer_D_B_state': optimizer_D_B.state_dict(),
        'scheduler_G_state': scheduler_G.state_dict(),
        'scheduler_D_A_state': scheduler_D_A.state_dict(),
        'scheduler_D_B_state': scheduler_D_B.state_dict(),
        'mapping_type': mapping_type,
        'n_resnet': n_resnet_val # Save n_resnet value passed to train function
    }
    filename = os.path.join(checkpoint_dir, f'checkpoint_{mapping_type}_epoch{epoch:03d}_{timestamp}.pth')
    try:
        torch.save(checkpoint, filename)
        print(f'>Checkpoint saved: {filename}')
    except Exception as e:
        print(f"Error saving checkpoint {filename}: {e}", file=sys.stderr)

def load_checkpoint(checkpoint_path, g_model_AtoB, g_model_BtoA, d_model_A, d_model_B,
                    optimizer_G, optimizer_D_A, optimizer_D_B,
                    scheduler_G, scheduler_D_A, scheduler_D_B):
    """Loads training state from a checkpoint. Returns start_epoch."""
    if not os.path.exists(checkpoint_path):
        print(f"Error: Checkpoint file not found at {checkpoint_path}", file=sys.stderr)
        return 0 # Return start epoch 0 if checkpoint not found
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device)

        # Load model states
        g_model_AtoB.load_state_dict(checkpoint['g_model_AtoB_state'])
        g_model_BtoA.load_state_dict(checkpoint['g_model_BtoA_state'])
        d_model_A.load_state_dict(checkpoint['d_model_A_state'])
        d_model_B.load_state_dict(checkpoint['d_model_B_state'])

        # Load optimizer states
        optimizer_G.load_state_dict(checkpoint['optimizer_G_state'])
        optimizer_D_A.load_state_dict(checkpoint['optimizer_D_A_state'])
        optimizer_D_B.load_state_dict(checkpoint['optimizer_D_B_state'])

        # Load scheduler states carefully
        if 'scheduler_G_state' in checkpoint: scheduler_G.load_state_dict(checkpoint['scheduler_G_state'])
        else: print("Warning: Scheduler G state not found in checkpoint.")
        if 'scheduler_D_A_state' in checkpoint: scheduler_D_A.load_state_dict(checkpoint['scheduler_D_A_state'])
        else: print("Warning: Scheduler D_A state not found in checkpoint.")
        if 'scheduler_D_B_state' in checkpoint: scheduler_D_B.load_state_dict(checkpoint['scheduler_D_B_state'])
        else: print("Warning: Scheduler D_B state not found in checkpoint.")

        start_epoch = checkpoint.get('epoch', -1) + 1
        loaded_mapping = checkpoint.get('mapping_type', 'N/A')
        loaded_n_resnet = checkpoint.get('n_resnet', 'N/A') # Load n_resnet if saved
        print(f'>Loaded checkpoint from epoch {start_epoch - 1} (Mapping: {loaded_mapping}, ResNet blocks: {loaded_n_resnet})')

        return start_epoch
    except Exception as e:
        print(f"Error loading checkpoint {checkpoint_path}: {e}", file=sys.stderr)
        print("Starting training from epoch 0.")
        return 0

# ------------------------------
# Validation Epoch Function (Using update/compute)
# ------------------------------
def evaluate_epoch(g_model_AtoB, g_model_BtoA, val_loader,
                   criterion_cycle, criterion_identity,
                   psnr_metric, ssim_metric, device):
    """Calculates validation metrics for one epoch using torchmetrics update/compute."""
    g_model_AtoB.eval()
    g_model_BtoA.eval()
    val_metrics = {}
    total_loss_cycle = 0.0
    total_loss_id = 0.0
    # Reset metrics at the beginning of evaluation
    psnr_metric.reset()
    ssim_metric.reset()
    count = 0

    with torch.no_grad():
        for real_A, real_B in tqdm(val_loader, desc="Validation", leave=False, file=sys.stdout):
            real_A = real_A.to(device) # Should be [-1, 1]
            real_B = real_B.to(device) # Should be [-1, 1]

            # Apply padding
            real_A_padded = F.pad(real_A, (0, 0, 0, 0, 0, 1))
            real_B_padded = F.pad(real_B, (0, 0, 0, 0, 0, 1))

            # Generate fake images
            fake_B = g_model_AtoB(real_A_padded)
            fake_A = g_model_BtoA(real_B_padded)

            # Apply cropping
            fake_B = fake_B[:, :, :-1, :, :]
            fake_A = fake_A[:, :, :-1, :, :]

            # Cycle consistency (for loss calculation only)
            recov_A = g_model_BtoA(fake_B)
            recov_B = g_model_AtoB(fake_A)
            recov_A = recov_A[:, :, :-1, :, :]
            recov_B = recov_B[:, :, :-1, :, :]

            # Identity mapping (for loss calculation only)
            identity_A = g_model_BtoA(real_A_padded)
            identity_B = g_model_AtoB(real_B_padded)
            identity_A = identity_A[:, :, :-1, :, :]
            identity_B = identity_B[:, :, :-1, :, :]

            # Calculate and accumulate losses (targets are original unpadded inputs)
            loss_cycle_A = criterion_cycle(recov_A, real_A)
            loss_cycle_B = criterion_cycle(recov_B, real_B)
            total_loss_cycle += (loss_cycle_A.item() + loss_cycle_B.item()) * real_A.size(0)

            loss_id_A = criterion_identity(identity_A, real_A)
            loss_id_B = criterion_identity(identity_B, real_B)
            total_loss_id += (loss_id_A.item() + loss_id_B.item()) * real_A.size(0)

            # <<< Update metrics state >>>
            # Compare cropped fakes to original reals
            psnr_metric.update(fake_A, real_A)
            psnr_metric.update(fake_B, real_B) # Update with both directions
            ssim_metric.update(fake_A, real_A)
            ssim_metric.update(fake_B, real_B) # Update with both directions

            count += real_A.size(0)

    # <<< Compute final metrics >>>
    val_metrics['val_loss_cycle'] = total_loss_cycle / (2 * count) if count > 0 else 0
    val_metrics['val_loss_id'] = total_loss_id / (2 * count) if count > 0 else 0
    try:
        # Compute returns the average over all updates since the last reset
        val_metrics['val_psnr_avg'] = psnr_metric.compute().item() if count > 0 else 0.0
        val_metrics['val_ssim_avg'] = ssim_metric.compute().item() if count > 0 else 0.0
    except Exception as e:
        print(f"Error computing metrics: {e}", file=sys.stderr)
        val_metrics['val_psnr_avg'] = 0.0
        val_metrics['val_ssim_avg'] = 0.0

    # Reset metrics explicitly (though compute should reset)
    psnr_metric.reset()
    ssim_metric.reset()

    g_model_AtoB.train()
    g_model_BtoA.train()

    return val_metrics


# ------------------------------
# Training Loop
# ------------------------------
def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA,
          dataloader, val_dataloader,
          epochs=1, device='cpu', mapping_type='t2_flair', start_epoch=0,
          log_dir='output/logs', save_viz=True, viz_dir='output/visualization',
          use_tb=False, tb_dir='output/tensorboard', initial_lr=0.0002, n_resnet=6, args_ref=None):

    criterion_GAN = nn.MSELoss()
    criterion_cycle = nn.L1Loss()
    criterion_identity = nn.L1Loss()

    optimizer_G = optim.Adam(list(g_model_AtoB.parameters()) + list(g_model_BtoA.parameters()),
                             lr=initial_lr, betas=(0.5, 0.999))
    optimizer_D_A = optim.Adam(d_model_A.parameters(), lr=initial_lr, betas=(0.5, 0.999))
    optimizer_D_B = optim.Adam(d_model_B.parameters(), lr=initial_lr, betas=(0.5, 0.999))

    # Define LR Schedulers
    epoch_decay_start = epochs // 2
    def lr_lambda(epoch):
        current_epoch = epoch
        if current_epoch < epoch_decay_start: return 1.0
        else:
            decay_epochs = epochs - epoch_decay_start
            multiplier = 1.0 - (current_epoch - epoch_decay_start) / decay_epochs if decay_epochs > 0 else 0.0
            return max(0.0, multiplier)

    scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lr_lambda)
    scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lr_lambda)
    scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lr_lambda)

    # Instantiate Metrics (data_range=2.0 for [-1, 1])
    try:
        psnr_metric = PeakSignalNoiseRatio(data_range=2.0).to(device)
        ssim_metric = StructuralSimilarityIndexMeasure(data_range=2.0).to(device)
    except Exception as e:
         print(f"Error initializing metrics: {e}. Check torchmetrics installation.", file=sys.stderr)
         return

    # Load checkpoint if resume path provided
    current_epoch = start_epoch
    if args_ref and args_ref.resume is not None:
        # Pass n_resnet from args to load_checkpoint if needed for verification later
        current_epoch = load_checkpoint(args_ref.resume, g_model_AtoB, g_model_BtoA, d_model_A, d_model_B,
                                      optimizer_G, optimizer_D_A, optimizer_D_B,
                                      scheduler_G, scheduler_D_A, scheduler_D_B)
        print(f"Resuming training from epoch {current_epoch}")
        # Manually advance scheduler to the correct starting point state if needed
        # For LambdaLR, the state is loaded, but ensure subsequent steps use correct epoch
        scheduler_G.last_epoch = current_epoch - 1
        scheduler_D_A.last_epoch = current_epoch - 1
        scheduler_D_B.last_epoch = current_epoch - 1

    pool_A = []
    pool_B = []

    # Loss weights
    lambda_id = 5.0
    lambda_cycle = 10.0
    lambda_intensity = 2.0 # Weight for the masked L1 intensity loss

    os.makedirs(log_dir, exist_ok=True)
    logger = Logger(log_dir, mapping_type)
    # TODO: Implement finding and appending previous log if resuming
    # if current_epoch > 0: logger.append_from_file(find_latest_log(log_dir, mapping_type))

    writer = SummaryWriter(log_dir=tb_dir) if use_tb else None

    g_model_AtoB.train()
    g_model_BtoA.train()
    d_model_A.train()
    d_model_B.train()

    n_steps = len(dataloader)
    if n_steps == 0:
        print("Error: Training DataLoader is empty.", file=sys.stderr)
        if writer: writer.close() # Close writer if exiting early
        return

    print(f"Starting training from epoch {current_epoch} up to {epochs} epochs...")
    for epoch in range(current_epoch, epochs):
        current_lr = optimizer_G.param_groups[0]['lr']
        print(f"\n--- Epoch {epoch + 1}/{epochs} --- LR: {current_lr:.6e} ---")
        progress_bar = tqdm(dataloader, total=n_steps, desc=f"Epoch {epoch+1}/{epochs}", file=sys.stdout, dynamic_ncols=True)
        epoch_loss_G_total = 0.0
        epoch_loss_D_total = 0.0

        for i, batch in enumerate(progress_bar):
            if batch is None: continue
            try:
                 real_A, real_B, _ = batch
                 real_A = real_A.to(device, non_blocking=True)
                 real_B = real_B.to(device, non_blocking=True)
            except Exception as e:
                 print(f"Error unpacking/moving batch {i}: {e}", file=sys.stderr)
                 continue

            real_A_padded = F.pad(real_A, (0, 0, 0, 0, 0, 1))
            real_B_padded = F.pad(real_B, (0, 0, 0, 0, 0, 1))
            real_A_unpadded = real_A
            real_B_unpadded = real_B

            # --- Generator ---
            optimizer_G.zero_grad()

            fake_B = g_model_AtoB(real_A_padded)
            fake_A = g_model_BtoA(real_B_padded)
            fake_B = fake_B[:, :, :-1, :, :]
            fake_A = fake_A[:, :, :-1, :, :]

            identity_A = g_model_BtoA(real_A_padded)
            identity_B = g_model_AtoB(real_B_padded)
            identity_A = identity_A[:, :, :-1, :, :]
            identity_B = identity_B[:, :, :-1, :, :]
            loss_id_A = criterion_identity(identity_A, real_A_unpadded)
            loss_id_B = criterion_identity(identity_B, real_B_unpadded)
            loss_identity_raw = loss_id_A + loss_id_B

            # Check discriminator outputs before calculating loss
            pred_fake_B = d_model_B(fake_B)
            pred_fake_A = d_model_A(fake_A)
            # Ensure target shapes match discriminator output shapes
            valid_B = torch.ones_like(pred_fake_B, device=device)
            valid_A = torch.ones_like(pred_fake_A, device=device)
            loss_GAN_A2B = criterion_GAN(pred_fake_B, valid_B)
            loss_GAN_B2A = criterion_GAN(pred_fake_A, valid_A)
            loss_GAN_raw = loss_GAN_A2B + loss_GAN_B2A

            recov_A = g_model_BtoA(fake_B)
            recov_B = g_model_AtoB(fake_A)
            recov_A = recov_A[:, :, :-1, :, :]
            recov_B = recov_B[:, :, :-1, :, :]
            loss_cycle_A = criterion_cycle(recov_A, real_A_unpadded)
            loss_cycle_B = criterion_cycle(recov_B, real_B_unpadded)
            loss_cycle_raw = loss_cycle_A + loss_cycle_B

            # Intensity Loss - Adjust threshold for [-1, 1] range
            # Example: mask based on values significantly different from background (-1).
            mask_thresh = -0.8 # Threshold slightly above background
            mask_A = (real_A_unpadded > mask_thresh).float()
            mask_B = (real_B_unpadded > mask_thresh).float()
            loss_intensity_A = torch.sum(torch.abs(fake_B - real_B_unpadded) * mask_B) / (torch.sum(mask_B) + 1e-8)
            loss_intensity_B = torch.sum(torch.abs(fake_A - real_A_unpadded) * mask_A) / (torch.sum(mask_A) + 1e-8)
            loss_intensity_raw = loss_intensity_A + loss_intensity_B

            loss_G = loss_GAN_raw + (loss_cycle_raw * lambda_cycle) + (loss_identity_raw * lambda_id) + (loss_intensity_raw * lambda_intensity)
            loss_G.backward()
            optimizer_G.step()

            # --- Discriminator Update ---
            # Discriminator A
            optimizer_D_A.zero_grad()
            pred_real_A = d_model_A(real_A_unpadded)
            loss_D_A_real = criterion_GAN(pred_real_A, torch.ones_like(pred_real_A, device=device))
            fake_A_pool = update_image_pool(pool_A, fake_A)
            pred_fake_A = d_model_A(fake_A_pool)
            loss_D_A_fake = criterion_GAN(pred_fake_A, torch.zeros_like(pred_fake_A, device=device))
            loss_D_A = 0.5 * (loss_D_A_real + loss_D_A_fake)
            loss_D_A.backward()
            optimizer_D_A.step()

            # Discriminator B
            optimizer_D_B.zero_grad()
            pred_real_B = d_model_B(real_B_unpadded)
            loss_D_B_real = criterion_GAN(pred_real_B, torch.ones_like(pred_real_B, device=device))
            fake_B_pool = update_image_pool(pool_B, fake_B)
            pred_fake_B = d_model_B(fake_B_pool)
            loss_D_B_fake = criterion_GAN(pred_fake_B, torch.zeros_like(pred_fake_B, device=device))
            loss_D_B = 0.5 * (loss_D_B_real + loss_D_B_fake)
            loss_D_B.backward()
            optimizer_D_B.step()

            # Logging
            epoch_loss_G_total += loss_G.item()
            epoch_loss_D_total += (loss_D_A.item() + loss_D_B.item())

            log_freq = max(1, n_steps // 10) # Log ~10 times per epoch
            if (i + 1) % log_freq == 0 or (i + 1) == n_steps:
                metrics = {
                    'loss_D_A': loss_D_A.item(), 'loss_D_B': loss_D_B.item(),
                    'loss_G_total': loss_G.item(),
                    'loss_G_gan': loss_GAN_raw.item(), 'loss_G_cycle': loss_cycle_raw.item(),
                    'loss_G_identity': loss_identity_raw.item(), 'loss_G_intensity': loss_intensity_raw.item(),
                }
                logger.log(epoch, i, metrics)
                if writer:
                    global_step = epoch * n_steps + i
                    for k, v in metrics.items():
                        if isinstance(v, (int, float)):
                            writer.add_scalar(f"Train_iter/{mapping_type}_{k}", v, global_step)
                    writer.add_scalar(f"Progress/epoch", epoch + (i+1)/n_steps, global_step)

            if (i+1) % max(1, n_steps // 20) == 0:
                progress_bar.set_description(f"E{epoch+1} {i+1}/{n_steps}: DA {loss_D_A.item():.3f}, DB {loss_D_B.item():.3f}, G {loss_G.item():.3f}")

        # --- End of Epoch Actions ---
        avg_epoch_loss_G = epoch_loss_G_total / n_steps
        avg_epoch_loss_D = epoch_loss_D_total / n_steps
        print(f"Epoch {epoch+1} Average Train Loss: G={avg_epoch_loss_G:.4f}, D={avg_epoch_loss_D:.4f}")
        if writer:
             writer.add_scalar(f"Train_epoch/{mapping_type}_loss_G_avg", avg_epoch_loss_G, epoch)
             writer.add_scalar(f"Train_epoch/{mapping_type}_loss_D_avg", avg_epoch_loss_D, epoch)
             writer.add_scalar(f"Progress/learning_rate", current_lr, epoch)

        # Perform Validation
        if val_dataloader:
            val_metrics = evaluate_epoch(g_model_AtoB, g_model_BtoA, val_dataloader,
                                         criterion_cycle, criterion_identity,
                                         psnr_metric, ssim_metric, device)
            print(f"Epoch {epoch+1} Validation: CycleL={val_metrics['val_loss_cycle']:.4f}, IdL={val_metrics['val_loss_id']:.4f}, "
                  f"PSNR_Avg={val_metrics['val_psnr_avg']:.2f}, SSIM_Avg={val_metrics['val_ssim_avg']:.3f}")
            if writer:
                writer.add_scalar(f"Val_epoch/{mapping_type}_loss_cycle", val_metrics['val_loss_cycle'], epoch)
                writer.add_scalar(f"Val_epoch/{mapping_type}_loss_id", val_metrics['val_loss_id'], epoch)
                writer.add_scalar(f"Val_epoch/{mapping_type}_psnr_avg", val_metrics['val_psnr_avg'], epoch) # Use avg
                writer.add_scalar(f"Val_epoch/{mapping_type}_ssim_avg", val_metrics['val_ssim_avg'], epoch) # Use avg
            logger.log(epoch, n_steps, val_metrics) # Log combined validation metrics at epoch end


        # Step LR Schedulers AFTER optimizer steps and validation
        scheduler_G.step()
        scheduler_D_A.step()
        scheduler_D_B.step()

         # --- Save visualizations periodically ---
        viz_freq = 1 # Adjust frequency as needed (e.g., save every 5 epochs)
        if save_viz and visualize_sample_translations and (epoch + 1) % viz_freq == 0:
            print("Generating visualization plots...")
            current_epoch_label = f"epoch{epoch+1:03d}" # Create the label string
            viz_save_path = os.path.join(viz_dir, current_epoch_label) # Save in epoch-specific subfolder
            os.makedirs(viz_save_path, exist_ok=True)

            # Visualize training samples
            visualize_sample_translations(
                epoch_label=current_epoch_label + "_train", # Add suffix for clarity
                g_model_AtoB=g_model_AtoB,
                g_model_BtoA=g_model_BtoA,
                dataset=dataloader.dataset, # Pass the dataset object
                mapping_type=mapping_type,  # Pass the base mapping type
                device=device,
                save_dir=viz_save_path,      # Use the specific output path
                n_samples=3                 # Number of samples
            )

            # Visualize validation samples (if available)
            if val_dataloader and hasattr(val_dataloader, 'dataset'):
                 visualize_sample_translations(
                    epoch_label=current_epoch_label + "_val", # Add suffix for clarity
                    g_model_AtoB=g_model_AtoB,
                    g_model_BtoA=g_model_BtoA,
                    dataset=val_dataloader.dataset, # Pass the validation dataset object
                    mapping_type=mapping_type,      # Pass the base mapping type
                    device=device,
                    save_dir=viz_save_path,          # Use the specific output path
                    n_samples=3                     # Number of samples
                 )
            elif val_dataloader:
                 print("Warning: val_dataloader provided but does not have a .dataset attribute. Skipping validation visualization.")


        # Save periodic models (optional)
        model_save_freq = 25
        if (epoch + 1) % model_save_freq == 0:
             model_save_dir = os.path.join(log_dir,'..','models', mapping_type) # Subfolder per mapping
             save_models(epoch, g_model_AtoB, g_model_BtoA, mapping_type, save_dir=model_save_dir)

        # Save checkpoint at the end of each epoch
        checkpoint_dir = os.path.join(log_dir,'..','checkpoints', mapping_type) # Subfolder per mapping
        save_checkpoint(epoch, g_model_AtoB, g_model_BtoA, d_model_A, d_model_B,
                        optimizer_G, optimizer_D_A, optimizer_D_B,
                        scheduler_G, scheduler_D_A, scheduler_D_B,
                        mapping_type, n_resnet_val=n_resnet, # Pass n_resnet here
                        checkpoint_dir=checkpoint_dir)

        logger.save() # Save JSON log file at end of each epoch
        if writer: writer.flush()

    # Final cleanup
    if writer: writer.close()
    print("Training finished.")


# ------------------------------
# Main Execution
# ------------------------------
if __name__ == '__main__':

    global device
    # ------------------------------
    # Check Environment and GPU
    # ------------------------------
    print("--- Environment Check ---")
    print(f"Python Version: {sys.version.split()[0]}")
    print(f"PyTorch Version: {torch.__version__}")
    print(f"Torchio Version: {tio.__version__}")
    try:
        print(f"TorchMetrics Version: {torchmetrics.__version__}")
    except Exception: print("TorchMetrics Version: (could not determine)")

    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        try:
            device = torch.device("cuda")
            print(f"Using device: {device} ({torch.cuda.get_device_name(device)})")
            x = torch.randn(1).to(device); print("GPU test successful.")
        except Exception as e:
            print(f"GPU test failed: {e}. Falling back to CPU.", file=sys.stderr)
            device = torch.device("cpu")
    else:
        device = torch.device("cpu")
        print("CUDA not available. Using device: cpu")
    print("-------------------------")
    # --- End of Environment Check ---
    
    parser = argparse.ArgumentParser(description='Train 3D CycleGAN for MRI Data Augmentation')
    parser.add_argument('--mapping_type', type=str, default='t2_flair', choices=['t2_flair', 't1_contrast'],
                        help='Mapping type to train: t2_flair or t1_contrast')
    parser.add_argument('--epochs', type=int, default=100, help='Number of training epochs')
    parser.add_argument('--data_dir', type=str,
                        default=r'./data/processed_data/brats128_training/images',
                        help='Directory containing [0,1] normalized TRAINING .npy volumes (output of splitfolders)')
    parser.add_argument('--val_data_dir', type=str,
                        default=r'./data/processed_data/brats128_validation/images',
                        help='Directory containing [0,1] normalized VALIDATION .npy volumes (output of splitfolders)')
    parser.add_argument('--resume', type=str, default=None, help='Path to checkpoint file (.pth) to resume from')
    parser.add_argument('--output_base_dir', type=str, default='./output', help='Base directory for logs, viz, tb, checkpoints, models')
    parser.add_argument('--log_dir', type=str, default='./output/logs', help='Directory to save training logs')
    parser.add_argument('--viz_dir', type=str, default='./output/visualization', help='Directory to save visualizations')
    parser.add_argument('--no_viz', action='store_true', help='Disable saving visualizations')
    parser.add_argument('--use_tb', action='store_true', help='Enable TensorBoard logging')
    parser.add_argument('--lr', type=float, default=0.0002, help='Initial learning rate')
    parser.add_argument('--n_resnet', type=int, default=6, help='Number of ResNet blocks in Generator (e.g., 6 or 9)')
    parser.add_argument('--num_workers', type=int, default=4, help='Number of DataLoader workers (set based on CPU cores)')

    args = parser.parse_args()

    # Derive specific output paths
    output_base_dir = os.path.abspath(os.path.expanduser(args.output_base_dir)) # Handle ~ and make absolute
    log_dir = os.path.join(output_base_dir, args.mapping_type, 'logs')
    viz_dir = os.path.join(output_base_dir, args.mapping_type, 'visualization')
    tb_dir = os.path.join(output_base_dir, args.mapping_type, 'tensorboard')
    # Checkpoint/model dirs created relative to log_dir/output_base_dir inside functions

    # Convert data paths to absolute paths
    args.data_dir = os.path.abspath(os.path.expanduser(args.data_dir))
    if args.val_data_dir:
        args.val_data_dir = os.path.abspath(os.path.expanduser(args.val_data_dir))
    if args.resume:
        args.resume = os.path.abspath(os.path.expanduser(args.resume))

    # Create base output directories
    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(viz_dir, exist_ok=True)
    if args.use_tb: os.makedirs(tb_dir, exist_ok=True)

    # Print configuration
    print("--- Configuration ---")
    print(f"Mapping Type:       {args.mapping_type}")
    print(f"Epochs:             {args.epochs}")
    print(f"Learning Rate:      {args.lr}")
    print(f"ResNet Blocks:      {args.n_resnet}")
    print(f"Batch Size:         1 (fixed)")
    print(f"Device:             {device}")
    print(f"Training Data:      {args.data_dir}")
    print(f"Validation Data:    {args.val_data_dir if args.val_data_dir else 'N/A'}")
    print(f"Resume Checkpoint:  {args.resume if args.resume else 'N/A'}")
    print(f"Log Directory:      {log_dir}")
    print(f"Viz Directory:      {viz_dir}")
    print(f"TensorBoard Dir:    {tb_dir if args.use_tb else 'N/A'}")
    print(f"Save Visuals:       {not args.no_viz}")
    print(f"Use TensorBoard:    {args.use_tb}")
    print(f"Num Workers:        {args.num_workers}")
    print("---------------------")

    # Define Torchio Augmentation Pipeline
    # Pad with -1 because data range is [-1, 1] after rescaling in dataset
    augment_pipeline = tio.Compose([
        tio.RandomAffine(scales=(0.9, 1.1), degrees=10, translation=10, isotropic=True, default_pad_value=-1, image_interpolation='bspline', p=0.75),
        #tio.RandomElasticDeformation(num_control_points=7, max_displacement=7.5, locked_borders=2, image_interpolation='bspline', p=0.5),
        tio.RandomFlip(axes=(0, 1, 2), flip_probability=0.25),
        tio.RandomBiasField(coefficients=0.3, order=3, p=0.3),
        tio.RandomNoise(std=(0, 0.05), p=0.25), # Std dev relative to [-1, 1] range
        tio.RandomGamma(log_gamma=(-0.2, 0.2), p=0.3),
    ])

    # --- Create datasets and dataloaders ---
    try:
        train_dataset = PairedPreprocessedDataset(args.data_dir, args.mapping_type, augment=True, torchio_transform=augment_pipeline)
        if len(train_dataset) == 0: raise ValueError("Training dataset is empty.")
        # Adjust num_workers based on system capabilities
        num_workers = min(args.num_workers, os.cpu_count() // 2 if os.cpu_count() else 1)
        train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=num_workers > 0 if torch.__version__ >= "1.7" else False)
        print(f"Training dataset: {len(train_dataset)} samples found. Using {num_workers} workers.")
    except Exception as e:
        print(f"Fatal Error: Failed to create training dataset/loader from {args.data_dir}: {e}", file=sys.stderr)
        sys.exit(1)

    val_dataloader = None
    if args.val_data_dir and os.path.exists(args.val_data_dir):
        try:
            val_dataset = PairedPreprocessedDataset(args.val_data_dir, args.mapping_type, augment=False)
            if len(val_dataset) > 0:
                num_workers = min(args.num_workers, os.cpu_count() // 2 if os.cpu_count() else 1)
                val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=num_workers > 0 if torch.__version__ >= "1.7" else False)
                print(f"Validation dataset: {len(val_dataset)} samples found. Using {num_workers} workers.")
            else:
                print(f"Warning: Validation directory '{args.val_data_dir}' exists but contains no .npy files.")
        except Exception as e:
            print(f"Warning: Failed to create validation dataset/loader from {args.val_data_dir}: {e}", file=sys.stderr)
    elif args.val_data_dir:
         print(f"Warning: Validation data directory not found: {args.val_data_dir}. Skipping validation loop.")
    else:
         print("Validation data directory not specified. Skipping validation loop.")


    # Optionally display some augmented slices for debugging
    if not args.no_viz and len(train_dataset) > 0:
        print("Checking dataset loading and augmentation (displaying one sample)...")
        try:
            sample_A, sample_B = train_dataset[0]
            print(f"Sample A shape: {sample_A.shape}, Range: {sample_A.min().item():.2f} to {sample_A.max().item():.2f}")
            print(f"Sample B shape: {sample_B.shape}, Range: {sample_B.min().item():.2f} to {sample_B.max().item():.2f}")
            if 'display_random_slices' in globals() and callable(display_random_slices):
                 if sample_A.shape[1] > 0:
                     display_random_slices(sample_A.numpy(), n_slices=5)
                 if sample_B.shape[1] > 0:
                     display_random_slices(sample_B.numpy(), n_slices=5)
                 else:
                     print("Warning: Sample A has depth 0, cannot display slice.")
            else:
                print("Skipping sample display (display_random_slices not available).")
        except Exception as e:
            print(f"Error loading or displaying sample data: {e}", file=sys.stderr)

    # Define input and output channels
    in_channels = 1
    out_channels = 1

    # Instantiate models
    try:
        d_model_A = Discriminator3D(in_channels).to(device)
        d_model_B = Discriminator3D(out_channels).to(device)
        g_model_AtoB = Generator3D(in_channels, out_channels, n_resnet=args.n_resnet).to(device)
        g_model_BtoA = Generator3D(out_channels, in_channels, n_resnet=args.n_resnet).to(device)
        # print("Attempting to compile models with torch.compile...")
        # Use a try-except block for compatibility with older PyTorch versions
        # try:
            # Recommended mode for general use cases
            # compile_mode = "default"
            # compile_mode = "reduce-overhead" # Use if compilation time is too long
            # compile_mode = "max-autotune" # Use for potentially best runtime speed, longer compile time

            # Only compile if PyTorch version supports it (>= 2.0)
            # if hasattr(torch, 'compile'):
            #      g_model_AtoB = torch.compile(g_model_AtoB, mode=compile_mode)
            #      g_model_BtoA = torch.compile(g_model_BtoA, mode=compile_mode)
            #      d_model_A = torch.compile(d_model_A, mode=compile_mode)
            #      d_model_B = torch.compile(d_model_B, mode=compile_mode)
            #      print("Models compiled successfully.")
            # else:
            #      print("torch.compile not available (requires PyTorch 2.0+). Running in eager mode.")

        # except Exception as compile_error:
        #     print(f"Warning: torch.compile failed: {compile_error}", file=sys.stderr)
        #     print("Running in standard eager mode.")
        # ---------------------------------------------------------------------

    except Exception as e:
         print(f"Fatal Error: Failed to initialize or compile models: {e}", file=sys.stderr)
         sys.exit(1)

    # Print model summary
    try:
        d, h, w = (135, 160, 160) # Default based on preprocessing crop
        if 'sample_A' in locals() and sample_A is not None:
             _, d_s, h_s, w_s = sample_A.shape
             if d_s > 0: d, h, w = d_s, h_s, w_s # Use actual shape if valid
        else:
             print("Warning: Using estimated shape for model summary.")

        print(f"\n--- Generator Info (Input: {in_channels}x{d}x{h}x{w}) ---")
        print(f"Using {args.n_resnet} ResNet blocks.")
        summary_device = str(device).split(":")[0] # 'cuda' or 'cpu'
        summary(g_model_AtoB, input_size=(in_channels, d, h, w), device=summary_device)
        print("------------------------------------------\n")
    except Exception as e:
        print(f"Could not print model summary: {e}", file=sys.stderr)

    # Start training
    start_epoch = 0 # Will be updated by load_checkpoint if resuming
    try:
        train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA,
              train_dataloader, val_dataloader,
              epochs=args.epochs, device=device, mapping_type=args.mapping_type, start_epoch=start_epoch,
              log_dir=log_dir, save_viz=not args.no_viz, viz_dir=viz_dir,
              use_tb=args.use_tb, tb_dir=tb_dir, initial_lr=args.lr, n_resnet=args.n_resnet, args_ref=args)
    except KeyboardInterrupt:
         print("\nTraining interrupted by user.")
         sys.exit(0)
    except Exception as e:
         print(f"\n--- Training Loop Error ---", file=sys.stderr)
         print(f"{type(e).__name__}: {e}", file=sys.stderr)
         import traceback
         traceback.print_exc()
         print("---------------------------", file=sys.stderr)
         sys.exit(1) # Exit with error code

